{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqlZpKh26EeIFuVJ8h/c3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalipaladi/Named-Entity-Recognition/blob/main/chatbott%20indian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import atexit\n",
        "import shutil\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "\n",
        "model_name = \"facebook/blenderbot-1B-distill\"\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def interact_with_chatbot(user_input,conversation_history):\n",
        "  conversation_history.append(f\"User:{user_input}\")\n",
        "  conversation_text= \" \".join(conversation_history[-5:])\n",
        "\n",
        "  inputs = tokenizer(conversation_text, return_tensors=\"pt\", truncation=True)\n",
        "  reply_ids = model.generate(**inputs,max_length=1000,pad_token_id=tokenizer.eos_token_id)\n",
        "  reply = tokenizer.batch_decode(reply_ids[0], skip_special_tokens=True)\n",
        "\n",
        "  conversation_history.append(f\"Chatbot: {reply}\")\n",
        "  return reply\n",
        "\n",
        "\n",
        "def delete_model_files():\n",
        "  cache_dir =os.path.expanduser(\"~/.cache/huggingface/hub/models--facebook--blenderbot-1B-distill\")\n",
        "  if os.path.exists(cache_dir):\n",
        "    user_input = input(\"Do you want to delete the model files? (yes/no): \")\n",
        "    if user_input.lower() == \"yes\":\n",
        "      shutil.rmtree(cache_dir)\n",
        "      print(f\"Deleted model files from cache directory: {cache_dir}\")\n",
        "    else:\n",
        "      print(\"Model files will not be deleted.\")\n",
        "  else:\n",
        "    print(f\"Model files not found in cache directory: {cache_dir}\")\n",
        "atexit.register(delete_model_files)\n",
        "\n",
        "print(\"Welcome to the Indian Tourism Chatbot!\")\n",
        "print(\"Type 'quit' to end the conversation.\\n\")\n",
        "\n",
        "conversation_history = []\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() == \"quit\":\n",
        "    print(\"Thankyou for using the Indian Tourism Chatbot. GoodBye!\")\n",
        "    break\n",
        "  reply = interact_with_chatbot(user_input,conversation_history)\n",
        "  print(f\"Chatbot: {reply}\")"
      ],
      "metadata": {
        "id": "tfTi1X0fqRJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OjqrGIyrHw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import atexit\n",
        "\n",
        "import shutil\n",
        "\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Load the pre-trained BlenderBot model and tokenizer\n",
        "\n",
        "model_name = \"facebook/blenderbot-1B-distill\"\n",
        "\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Step 2: Define a function to interact with the chatbot\n",
        "\n",
        "def interact_with_chatbot(user_input, conversation_history):\n",
        "\n",
        "    # Step 2.1: Add user input to the conversation history\n",
        "\n",
        "    conversation_history.append(f\"User: {user_input}\")\n",
        "\n",
        "    # Step 2.2: Prepare the input text for the model\n",
        "\n",
        "    conversation_text = \" \".join(conversation_history[-5:])  # Use only the last 5 exchanges to keep context manageable\n",
        "\n",
        "    # Step 2.3: Generate a response using the chatbot pipeline\n",
        "\n",
        "    inputs = tokenizer(conversation_text, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "    response_ids = model.generate(**inputs, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    response_text = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Step 2.4: Add the generated response to the conversation history\n",
        "\n",
        "    conversation_history.append(f\"Chatbot: {response_text}\")\n",
        "    return response_text\n",
        "\n",
        "\n",
        "# Step 3: Define a function to delete the model files from the cache directory\n",
        "\n",
        "def delete_model_files():\n",
        "\n",
        "    cache_dir = os.path.expanduser(\"~/.cache/huggingface/hub/models--facebook--blenderbot-1B-distill\")\n",
        "\n",
        "    if os.path.exists(cache_dir):\n",
        "\n",
        "        user_input = input(\"Do you want to delete the model files from the cache directory? (y/n): \")\n",
        "\n",
        "        if user_input.lower() == 'y':\n",
        "\n",
        "            shutil.rmtree(cache_dir)\n",
        "\n",
        "            print(f\"Deleted model files from cache directory: {cache_dir}\")\n",
        "\n",
        "        else:\n",
        "\n",
        "            print(\"Model files not deleted from cache directory.\")\n",
        "\n",
        "    else:\n",
        "\n",
        "        print(f\"Model files not found in cache directory: {cache_dir}\")\n",
        "\n",
        "\n",
        "# Step 4: Register the delete_model_files function to be called on program exit\n",
        "\n",
        "atexit.register(delete_model_files)\n",
        "\n",
        "# Step 5: Start the conversation loop\n",
        "\n",
        "print(\"Welcome to the Indian Tourism Chatbot!\")\n",
        "\n",
        "print(\"Type 'quit' to end the conversation.\\n\")\n",
        "\n",
        "conversation_history = []\n",
        "\n",
        "while True:\n",
        "\n",
        "    # Step 5.1: Get user input\n",
        "\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # Step 5.2: Check if the user wants to quit\n",
        "\n",
        "    if user_input.lower() == 'quit':\n",
        "\n",
        "        print(\"Thank you for using the Indian Tourism Chatbot. Goodbye!\")\n",
        "\n",
        "        break\n",
        "\n",
        "    # Step 5.3: Generate and print the chatbot's response\n",
        "\n",
        "    response = interact_with_chatbot(user_input, conversation_history)\n",
        "\n",
        "    print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwHuRLDUtrDB",
        "outputId": "b702ad62-5b59-4fef-87ff-7e3a246b9056"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Indian Tourism Chatbot!\n",
            "Type 'quit' to end the conversation.\n",
            "\n",
            "User: how are you\n",
            "Chatbot:  I'm doing well. How are you? What do you like to do in your spare time?\n",
            "User: suggest few places in hyderabad\n",
            "Chatbot:  I am doing well, thank you. I like to chat with my friends on chatbot.\n",
            "User: beach names in vijayawada\n",
            "Chatbot:  Vijaya is a beautiful place to visit. Have you ever been there before?\n",
            "User: quit\n",
            "Thank you for using the Indian Tourism Chatbot. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeJHQtpPtw6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}